

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introduction to Project ACRN &mdash; Project ACRN™ v 0.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/ACRN-favicon-32x32.png"/>
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/acrn-custom.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="Project ACRN™ v 0.1 documentation" href="../index.html"/>
        <link rel="next" title="Supported Hardware" href="../hardware.html"/>
        <link rel="prev" title="Introducing Project ACRN" href="index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Project ACRN™
          

          
            
            <img src="../_static/ACRN_Logo_300w.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                v 0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Introducing Project ACRN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#automotive-use-case-scenario">Automotive use case scenario</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction to Project ACRN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#licensing">Licensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#terminology">Terminology</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview-overview-for-what">2.3 Overview&nbsp;(overview for what??)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#acrn-device-model-service-os-and-user-os">2.3.1 ACRN Device Model, Service OS, and User OS</a></li>
<li class="toctree-l4"><a class="reference internal" href="#boot-sequence">2.3.2 Boot Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="#acrn-hypervisor-architecture">2.3.3 ACRN &nbsp;Hypervisor Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="#acrn-device-model">2.3.4 ACRN Device Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pass-through">2.3.5 Pass through</a></li>
<li class="toctree-l4"><a class="reference internal" href="#acrn-i-o-mediator">2.3.6 ACRN I/O mediator</a></li>
<li class="toctree-l4"><a class="reference internal" href="#virtio-framework-architecture">2.3.7 VirtIO framework architecture</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../hardware.html">Supported Hardware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../hardware.html#intel-apollo-lake-nuc">Intel Apollo Lake NUC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/index.html">Getting Started Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hypervisor_primer/index.html">Hypervisor Developer Primer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../hypervisor_primer/index.html#source-tree-structure">Source Tree Structure</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contribution Guidelines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contribute.html#licensing">Licensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contribute.html#developer-certification-of-origin-dco">Developer Certification of Origin (DCO)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contribute.html#dco-sign-off-methods">DCO Sign-Off Methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contribute.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contribute.html#repository-layout">Repository layout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contribute.html#pull-requests-and-issues">Pull Requests and Issues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contribute.html#contribution-tools-and-git-setup">Contribution Tools and Git Setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contribute.html#signed-off-by">Signed-off-by</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contribute.html#coding-style">Coding Style</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contribute.html#contribution-workflow">Contribution Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contribute.html#commit-guidelines">Commit Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contribute.html#commit-message-body">Commit Message Body</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contribute.html#other-commit-expectations">Other Commit Expectations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contribute.html#identifying-contribution-origin">Identifying Contribution Origin</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/hypercall_api.html">Hypercall APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/devicemodel_api.html">Device Model APIs</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Project ACRN™</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Introduction to Project ACRN</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="introduction-to-project-acrn">
<span id="introduction"></span><h1>Introduction to Project ACRN<a class="headerlink" href="#introduction-to-project-acrn" title="Permalink to this headline">¶</a></h1>
<p>The open source project ACRN defines a device hypervisor reference stack
and an architecture for running multiple software subsystems, managed
securely, on a consolidated system by means of a virtual machine
manager. It also defines a reference framework implementation for
virtual device emulation, called the “ACRN Device Model”.</p>
<p>The ACRN Hypervisor is a Type 1 reference hypervisor stack, running
directly on the bare-metal hardware, and is suitable for a variety of
IoT and embedded device solutions. The ACRN hypervisor addresses the gap
that currently exists between datacenter hypervisors, and hard
partitioning hypervisors. The ACRN hypervisor architecture partitions
the system into different functional domains, with carefully selected
guest OS sharing optimiztionsfor IoT and embedded devices.</p>
<p>An interesting use case example for the ACRN Hypervisor is in automotive
scenario.  The ACRN hypervisor can be used for building a Software
Defined Cockpit (SDC) or an In-Vehicle Experience (IVE) solution.  As a
reference implementation, ACRN provides the basis for embedded
hypervisor vendors to build solutions with a reference I/O mediation
solution.</p>
<p>In this scenario, an automotive SDC system consists of the Instrument
Cluster (IC) system, the In-Vehicle Infotainment (IVI) system, and one
or more Rear Seat Entertainment (RSE) systems. Each system is running as
an isolated Virtual Machine (VM) for overall system safety
considerations.</p>
<p>An <strong>Instrument Cluster (IC)</strong> system is used to show the driver operational
information about the vehicle, such as:</p>
<ul class="simple">
<li>the speed, the fuel level, trip mile and other driving information of
the car;</li>
<li>projecting heads-up images on the windshield, with alerts for low
fuel or tire pressure;</li>
<li>showing rear-view camera, and surround-view for parking assistance.</li>
</ul>
<p>An <strong>In-Vehicle Infotainment (IVI)</strong> system’s capabilities can include:</p>
<ul class="simple">
<li>navigation systems, radios, and other entertainment systems;</li>
<li>connection to mobile devices for phone calls, music, and applications
via voice recognition;</li>
<li>control interaction by gesture recognition or touch.</li>
</ul>
<p>A <strong>Rear Seat Entertainment (RSE)</strong> system could run:</p>
<ul class="simple">
<li>entertainment system;</li>
<li>virtual office;</li>
<li>connection to the front-seat IVI system&nbsp;and mobile devices (cloud
connectivity).</li>
<li>connection to mobile devices for phone calls, music, and
applications via voice recognition;</li>
<li>control interaction by gesture recognition or touch</li>
</ul>
<p>The ACRN hypervisor can support both Linux* VM and Android* VM as a
User OS, with the User OS managed by the ACRN hypervisor. Developers and
OEMs can use this reference stack to run their own VMs, together with
IC, IVI, and RSE VMs. The Service OS runs as VM0 (also known as Dom0 in
other hypervisors) and the User OS runs as VM1, (also known as DomU).</p>
<p><a class="reference internal" href="#ivi-block"><span class="std std-numref">Figure 1</span></a> shows an example block diagram of using the ACRN
hypervisor.</p>
<div class="figure align-center" id="ivi-block">
<img alt="../_images/IVI-block.png" src="../_images/IVI-block.png" />
<p class="caption"><span class="caption-number">Figure 1 </span><span class="caption-text">Service OS and User OS on top of ACRN hypervisor</span></p>
</div>
<p>This ACRN hypervisor block diagram shows:</p>
<ul class="simple">
<li>The ACRN hypervisor sits right on top of the bootloader for fast
booting capabilities.</li>
<li>Partitioning of resources to ensure safety-critical and non-safety
critical domains are able to coexist on one platform.</li>
<li>Rich I/O mediators allows various I/O devices shared across VMs, and
thus delivers a comprehensive user experience</li>
<li>Multiple operating systems are supported by one SoC through efficient
virtualization.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The yellow color parts in <a class="reference internal" href="#ivi-block"><span class="std std-numref">Figure 1</span></a> are part of the project
ACRN software stack. This is a reference architecture diagram and not
all features mentioned are fully functional. Other blocks will come from
other (open source) projects and are listed here for reference only.</p>
<p>For example: the Service OS and Linux Guest can come from the Clear
Linux project at <a class="reference external" href="https://clearlinux.org">https://clearlinux.org</a> and (in later updates) the
Android as a Guest support can come from <a class="reference external" href="https://01.org/android-ia">https://01.org/android-ia</a>.</p>
<p class="last">For the current ACRN-supported feature list, please see
<a class="reference internal" href="../release_notes.html#release-notes"><span class="std std-ref">Release Notes</span></a>.</p>
</div>
<div class="section" id="licensing">
<h2>Licensing<a class="headerlink" href="#licensing" title="Permalink to this headline">¶</a></h2>
<p>Both the ACRN hypervisor and ACRN Device model software are provided
under the permissive <a class="reference external" href="https://opensource.org/licenses/BSD-3-Clause">BSD-3-Clause</a> license, which allows
<em>“redistribution and use in source and binary forms, with or without
modification”</em> together with the intact copyright notice and
disclaimers noted in the license.</p>
</div>
<div class="section" id="terminology">
<h2>Terminology<a class="headerlink" href="#terminology" title="Permalink to this headline">¶</a></h2>
<table border="1" class="colwidths-auto docutils" id="id3">
<caption><span class="caption-number">Table 1 </span><span class="caption-text">Terminology</span><a class="headerlink" href="#id3" title="Permalink to this table">¶</a></caption>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Term</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ACPI</td>
<td>Advanced Configuration and Power Interface</td>
</tr>
<tr class="row-odd"><td>BIOS</td>
<td>Basic Input/Output System</td>
</tr>
</tbody>
</table>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>Term</td>
<td>Description</td>
</tr>
<tr class="row-even"><td>ACPI</td>
<td>Advanced Configuration and Power
Interface</td>
</tr>
<tr class="row-odd"><td>BIOS</td>
<td>Basic Input/Output System.</td>
</tr>
<tr class="row-even"><td>GPU</td>
<td>Graphics Processing Unit</td>
</tr>
<tr class="row-odd"><td>I2C</td>
<td>Inter-Integrated Circuit</td>
</tr>
<tr class="row-even"><td>IC</td>
<td>Instrument Cluster</td>
</tr>
<tr class="row-odd"><td>IVE</td>
<td>In-Vehicle Experience</td>
</tr>
<tr class="row-even"><td>IVI</td>
<td>In-vehicle Infotainment</td>
</tr>
<tr class="row-odd"><td>OS</td>
<td>Operating System</td>
</tr>
<tr class="row-even"><td>OSPM</td>
<td>Operating System Power Management</td>
</tr>
<tr class="row-odd"><td>PCI</td>
<td>Peripheral Component Interface.</td>
</tr>
<tr class="row-even"><td>PM</td>
<td>Power Management</td>
</tr>
<tr class="row-odd"><td>Pass-Through Devices</td>
<td>Physical devices (typically PCI)
exclusively assigned to a guest.
&nbsp;In this architecture,
pass-through devices are owned by
the foreground OS.</td>
</tr>
<tr class="row-even"><td>PV</td>
<td>Para-virtualization&nbsp;-<a class="reference external" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Paravirtualization&amp;sa=D&amp;ust=1520533207654000&amp;usg=AFQjCNHzUPHU6bvKYF5ZDSDknq9sgUtM9g">https://e
n.wikipedia.org/wiki/Paravirtuali
zation</a></td>
</tr>
<tr class="row-odd"><td>RSE</td>
<td><p class="first">Rear</p>
<p class="last">Seat Entertainment</p>
</td>
</tr>
<tr class="row-even"><td>SDC</td>
<td>Software Defined Cockpit</td>
</tr>
<tr class="row-odd"><td>SOS</td>
<td>Service OS</td>
</tr>
<tr class="row-even"><td>UEFI</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>UOS</td>
<td>User OS</td>
</tr>
<tr class="row-even"><td>VHM</td>
<td>Virtio and Hypervisor Service
Module</td>
</tr>
<tr class="row-odd"><td>VM</td>
<td>Virtual Machine</td>
</tr>
<tr class="row-even"><td>VMM</td>
<td>Virtual Machine Monitor</td>
</tr>
<tr class="row-odd"><td>VMX</td>
<td>Virtual Machine Extension</td>
</tr>
<tr class="row-even"><td>Virtio-BE</td>
<td>Back-End, VirtIO framework
provides front-end driver and
back-end driver for IO mediators,
developer has habit of using
Shorthand. So they say Virtio-BE
and Virtio-FE</td>
</tr>
<tr class="row-odd"><td>Virtio-FE</td>
<td>Front-End, VirtIO framework
provides front-end driver and
back-end driver for IO mediators,
developer has &nbsp;habit of using
Shorthand. So they say Virtio-BE
and Virtio-FE</td>
</tr>
<tr class="row-even"><td>VT</td>
<td>Intel Virtualization Technology</td>
</tr>
<tr class="row-odd"><td>VT-d</td>
<td>Virtualization Technology for
Directed I/O</td>
</tr>
</tbody>
</table>
<div class="section" id="overview-overview-for-what">
<span id="h-gbjy1p4qbcf8"></span><h3>2.3 Overview&nbsp;(overview for what??)<a class="headerlink" href="#overview-overview-for-what" title="Permalink to this headline">¶</a></h3>
<div class="section" id="acrn-device-model-service-os-and-user-os">
<span id="h-dnoapo3mv5wn"></span><h4>2.3.1 ACRN Device Model, Service OS, and User OS<a class="headerlink" href="#acrn-device-model-service-os-and-user-os" title="Permalink to this headline">¶</a></h4>
<p>To keep the hypervisor code base as small and efficient as possible, the
bulk of the device model implementation resides in the Service OS to
provide &nbsp;sharing and other capabilities. The details of which devices
are shared and the mechanism used for their sharing is described in
section&nbsp;2.3.5.</p>
<p>The Service&nbsp;OS runs with the system’s highest virtual machine priority
to ensure required device time-sensitive requirements and system quality
of service (QoS). Service OS tasks run with mixed priority. Upon a
callback servicing a particular User OS request, the corresponding
software (or mediator) in the Service OS inherits the User OS priority.
There may also be additional low-priority background tasks within the
Service OS.</p>
<p>In the automotive example, the User OS is the central hub of vehicle
control and in-vehicle entertainment. It provides support for radio and
entertainment options, control of the vehicle climate control, and
vehicle navigation displays. It also provides connectivity using USB,
Bluetooth, and/or WiFi&nbsp;for third-party device interaction with the
vehicle, such as Android Auto* or Apple CarPlay*, and many other
features.</p>
</div>
<div class="section" id="boot-sequence">
<span id="h-yfxp9sdoci8m"></span><h4>2.3.2 Boot Sequence<a class="headerlink" href="#boot-sequence" title="Permalink to this headline">¶</a></h4>
<p>Here we are using a verified Boot Sequence with UEFI as a sample on
Intel® Architecture platform <a class="reference external" href="https://www.google.com/url?q=https://www.intel.com/content/www/us/en/products/boards-kits/nuc/kits/nuc6cayh.html&amp;sa=D&amp;ust=1520533207663000&amp;usg=AFQjCNEUngM1uACF16FYb9gUWZdsChNNEw">NUC Kit
NUC6CAYH</a>(<a class="reference external" href="https://www.google.com/url?q=https://ark.intel.com/products/95594/Intel-Celeron-Processor-J3455-2M-Cache-up-to-2_3-GHz&amp;sa=D&amp;ust=1520533207663000&amp;usg=AFQjCNERO4z2otTBTbaarufAfSrRlnnISw">Intel®
Celeron® Processor
J3455</a>)
&nbsp;- Figure 2.</p>
<p><img alt="image1" src="introduction/images/image7.png" /></p>
<p>Figure 2&nbsp;ACRN Hypervisor Boot Flow</p>
<p>Boot process as below:</p>
<p>•UEFI verifies and boots ACRN hypervisor &amp; Service OS Bootloader
(???Change the picture to SOS Bootloader???)</p>
<p>•UEFI (or Service OS Bootloader) verifies and boots Service OS kernel</p>
<p>•Service OS kernel verifies and loads ACRN Device Model and Virtual
bootloader through dm-verity</p>
<p>•Virtual bootloader starts the User side verified boot process</p>
<p>&nbsp;(??? Shoudl we add a box of “UOS Kernel” in Figure 2???”)</p>
<p>In the ACRN project, the github provides ACRN hypervisor and ACRN Device
model only, however, you should have below list ready to run a complete
validation or development on <a class="reference external" href="https://www.google.com/url?q=https://www.intel.com/content/www/us/en/products/boards-kits/nuc/kits/nuc6cayh.html&amp;sa=D&amp;ust=1520533207665000&amp;usg=AFQjCNEyVFNuwdVUfDTlu2S1xzKSHrK0Bw">NUC Kit
NUC6CAYH</a>:</p>
<p>1, User may need install or update latest UEFI firmware for the
hardware, UEFI firmware for the <a class="reference external" href="https://www.google.com/url?q=https://www.intel.com/content/www/us/en/products/boards-kits/nuc/kits/nuc6cayh.html&amp;sa=D&amp;ust=1520533207666000&amp;usg=AFQjCNFIYKgJZ9lWrzJyvU3jwGRNI1Qbiw">NUC Kit
NUC6CAYH</a>&nbsp;need
to download and install <a class="reference external" href="https://www.google.com/url?q=https://downloadcenter.intel.com/search?keyword%3Dnuc6cayh%2Bbios&amp;sa=D&amp;ust=1520533207666000&amp;usg=AFQjCNHBb9eGthjVgug-SdlkBIkmuBnimQ">latest BIOS
version</a>.
(learn how to <a class="reference external" href="https://www.google.com/url?q=https://www.intel.com/content/www/us/en/support/articles/000005636.html&amp;sa=D&amp;ust=1520533207666000&amp;usg=AFQjCNE2p9KF8scsWRkzFxtAqbxocNQ7gA">update
BIOS</a>&nbsp;)</p>
<p>2, Refer to
<a class="reference external" href="https://www.google.com/url?q=https://github.com/clearlinux&amp;sa=D&amp;ust=1520533207667000&amp;usg=AFQjCNE4s78QghAzka7A5cOfpCr_EKNxmA">https://github.com/clearlinux</a>&nbsp;to
get Service OS and User OS reference implement for ACRN project.</p>
</div>
<div class="section" id="acrn-hypervisor-architecture">
<span id="h-nl4odhj4pa54"></span><h4>2.3.3 ACRN &nbsp;Hypervisor Architecture<a class="headerlink" href="#acrn-hypervisor-architecture" title="Permalink to this headline">¶</a></h4>
<p>ACRN hypervisor is a Type&nbsp;1&nbsp;hypervisor, running directly on bare-metal
hardware. It implements a hybrid VMM architecture, using a privileged
service VM, running the Service OS that manages the I/O devices and
provides&nbsp;I/O mediation. Multiple User VMs are supported, with each of
them running Linux*&nbsp;or Android*&nbsp;OS as the User OS .</p>
<p>For an automotive user case. by running the IC system in a separate VM,
it can be well isolated from other VMs and their applications, and
therefore reduce the attack surface and minimize safety interference.
However, running the IC system in a separate VM may introduces
additional latency for the IC applications.</p>
<p>Figure 3&nbsp;shows the ACRN hypervisor architecture, with the IC VM and
service VM together. The Service OS (SOS) owns most of the devices
including the platform devices, and provides I/O mediation. Some of the
PCIe devices may be passed through to the User OSes via the VM
configuration. The SOS runs the IC applications and hypervisor-specific
applications together, such as the ACRN device model, and ACRN VM
manager.</p>
<p>ACRN hypervisor also runs the ACRN VM manager to collect the running
information of the User OS, and controls the User VM such as starting,
stopping, and pausing a VM, pausing or resuming a virtual CPU, etc.</p>
<p><img alt="image2" src="introduction/images/image9.png" /></p>
<p>Figure 3 ACRN Hypervisor Architecture</p>
<p>ACRN hypervisor takes advantage of Intel Virtualization Technology
(Intel VT),&nbsp;and ACRN hypervisor runs in Virtual Machine Extension (VMX)
root operation, or host mode, or VMM mode. &nbsp;All the guests, including
UOS and SOS, run in VMX non-root operation, or guest mode. (Hereafter,
we use the terms VMM mode and Guest mode for simplicity).</p>
<p>The VMM mode has 4 protection rings, but it runs the ACRN hypervisor in
ring 0 privilege only, and leaves rings 1-3 unused. The guest&nbsp;(including
SOS &amp; UOS), running in Guest mode, also has its own four protection
rings (ring 0 to 3). The User kernel runs in ring 0 of guest mode, and
user land applications run in ring 3 of User mode (ring 1 &amp; 2 are
usually not used by commercial OSes).</p>
<p>&nbsp;<img alt="image3" src="introduction/images/image8.png" /></p>
<p>Figure 4 VMX Brief</p>
<p>VMM mode and guest mode are switched through VM Exit and VM Entry. When
the bootloader hands off control to the ACRN hypervisor, the processor
hasn’t enabled VMX operation yet. The ACRN hypervisor needs to enable
VMX operation thru a VMXON instruction first. Initially, the processor
stays in VMM mode when the VMX operation is enabled. It enters guest
mode thru a VM resume instruction (or first time VM launch), and returns
back to VMM mode thru a VM exit event. &nbsp;VM exit occurs in response to
certain instructions and events.</p>
<p>The behavior of processor execution in guest mode is controlled by a
virtual machine control structure (VMCS). VMCS contains the guest state
(loaded at VM Entry, and saved at VM Exit), the host state, (loaded at
the time of VM exit), and the guest execution controls. ACRN hypervisor
creates a VMCS data structure for each virtual CPU, and uses the VMCS to
configure the behavior of the processor running in guest mode.</p>
<p>When the execution of the guest hits a sensitive
instruction:sup:<a href="#id1"><span class="problematic" id="id2">``</span></a>[a] &lt;#cmnt1&gt;`__<a class="reference external" href="#cmnt2">[b]</a><a class="reference external" href="#cmnt3">[c]</a><cite>[d] &lt;#cmnt4&gt;`__</cite>(for
example:), a VM exit event may happen as defined in the VMCS
configuration. Control goes back to the ACRN hypervisor when the VM exit
happens. ACRN hypervisor emulates the guest instruction (if it is due to
privilege issue) and resumes the guest to its next instruction, or fix
the VM exit reason (for example if a guest memory page is not mapped
yet) and resume the guest to re-execute the instruction.</p>
<p>Note that the address space used in VMM mode is different from that in
guest mode. The guest mode and VMM mode use different memory mapping
tables, and therefore the ACRN hypervisor is protected from guest
access. The ACRN hypervisor uses EPT to map the guest address, using the
guest page table to map from guest linear address to guest physical
address, and using the EPT table to map from guest physical address to
machine physical address or host physical address (HPA).</p>
</div>
<div class="section" id="acrn-device-model">
<span id="h-ow376uumyc8t"></span><h4>2.3.4 ACRN Device Model<a class="headerlink" href="#acrn-device-model" title="Permalink to this headline">¶</a></h4>
<p>Let’s explore how device emulation works today in other hypervisor
architectures where device emulation is done within the hypervisor, or
where device emulation is pushed to an external application outside the
hypervisor.</p>
<p>The first architecture is device emulation within the hypervisor which
is &nbsp;a common method implemented within the VMware*&nbsp;workstation product
(an operating system-based hypervisor). In this method, the hypervisor
includes emulations of common devices that the various guest operating
systems can share, including virtual disks, virtual network adapters,
and other necessary platform elements.</p>
<p>The second &nbsp;architecture is called user space device emulation. As the
name implies, rather than the device emulation being embedded within the
hypervisor, it is instead implemented in a separate user space
application. QEMU provides this kind of device emulation and is used by
a large number of independent hypervisors. This model is advantageous,
because the device emulation is independent of the hypervisor and can
therefore be shared for other hypervisors. It also permits arbitrary
device emulation without having to burden the hypervisor&nbsp;(which operates
in a privileged state) with this functionality.</p>
<p>The third variation on hypervisor-based device emulation is
paravirtualized (PV) drivers. In this model introduced by the <a class="reference external" href="https://www.google.com/url?q=https://wiki.xenproject.org/wiki/Understanding_the_Virtualization_Spectrum&amp;sa=D&amp;ust=1520533207671000&amp;usg=AFQjCNFsQ8Qtl8lWxgKO_fDJsz1pcdYatA">XEN
project</a>,
the hypervisor includes the physical drivers, and each guest operating
system includes a hypervisor-aware driver that works in concert with the
hypervisor drivers.</p>
<p>In the device emulation models discussed above, there’s a price to pay
for sharing devices. Whether device emulation is performed in the
hypervisor, or in user space within an independent VM, overhead exists.
This overhead is worthwhile as long as the devices need to be shared by
multiple guest operating systems. If sharing is not necessary, then
there are more efficient methods for accessing devices, for example
“pass-through”.</p>
<p>ACRN device model is a placeholder of the UOS. It allocates memory for
the User OS, configures and initializes the devices used by the UOS,
loads the virtual firmware, initializes the virtual CPU state, and
invokes the ACRN hypervisor service to execute the guest instructions.
&nbsp;ACRN Device model is an application running in the Service OS that
emulates devices based on command line configuration, the architecture
as below -:</p>
<p><img alt="image4" src="introduction/images/image10.png" /></p>
<p>Figure 5 ACRN Device Model</p>
<p>(??? There’re two green boxed for vLAPIC???)</p>
<p>ACRN Device model involves&nbsp;below 3 aspects:</p>
<p>Device Emulation: ACRN Device model provides device emulation
routines,&nbsp;these routines register their I/O handlers to the I/O
dispatcher. When there is an I/O request from the User OS device, the
I/O dispatcher will dispatch this request to the corresponding device
emulation routine.</p>
<p>I/O Path: &nbsp;see section 2.3.6</p>
<p>VHM: The Virtio and Hypervisor Service Module is a kernel module in the
Service OS acting as a middle layer to support the device model. The VHM
and its client handling flow is described below:</p>
<ol class="arabic simple">
<li>ACRN hypervisor IOREQ is forwarded to the VHM by an upcall
notification to the SOS.</li>
<li>VHM will mark the IOREQ as “in process” so that the same IOREQ will
not pick up again. The IOREQ will be sent to the client for handling.
Meanwhile, the VHM is ready for another IOREQ.</li>
<li>IOREQ clients are either SOS Userland application or Service OS
Kernel space module. Once IOREQ is processed and completed, the
Client will issue an IOCTL call to the VHM to notify IOREQ state
change. The VHM then checks and hypercalls to ACRN hypervisor
notifying it that the IOREQ has completed.</li>
</ol>
<p>Note: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Userland: &nbsp;dm as ACRN Device Model. Kernel space: &nbsp;VBS-K,
MPT Service, VHM itself</p>
</div>
<div class="section" id="pass-through">
<span id="h-cr02ry2l08p3"></span><h4>2.3.5 Pass through<a class="headerlink" href="#pass-through" title="Permalink to this headline">¶</a></h4>
<p>At the highest level, device pass-through is about providing isolation
of a device to a given guest operating system so that the device can be
used exclusively by that guest.</p>
<p><img alt="image5" src="introduction/images/image5.png" /></p>
<p>Figure 6 Device Passthrough</p>
<p>Near to native performance can be achieved by using device passthrough.
This is perfect for networking applications (or those that have high
disk I/O) that have not adopted virtualization because of contention and
performance degradation through the hypervisor&nbsp;(to a driver in the
hypervisor or through the hypervisor to a user space emulation). But
assigning devices to specific guests is also useful when those devices
inherently wouldn’t be shared. For example, if a system includes
multiple video adapters, those adapters could be passed through to
unique guest domains.</p>
<p>Finally, there may be specialized PCI devices that only one guest domain
uses, so they should be passed through to the guest. Individual USB
ports could be isolated to a given domain too, or a serial port (which
is itself not shareable) could be isolated to a particular guest.this is
for general case, in ACRN hypervisor, we support USB controller Pass
through only and we don’t support pass through for a legacy serial
port,&nbsp;for example 0x3f8.</p>
<div class="section" id="hardware-support-for-device-passthrough">
<span id="h-rm7rcgdx4vep"></span><h5>2.3.5.1 Hardware support for device passthrough<a class="headerlink" href="#hardware-support-for-device-passthrough" title="Permalink to this headline">¶</a></h5>
<p>Intel’s current processor architectures provides support for device
pass-through with VT-d, VT-d maps guest physical address to machine
physical address, so device can use guest physical address directly.
When this mapping occurs, the hardware takes care of access (and
protection), and the guest operating system can use the device as if it
was &nbsp;a non-virtualized system. In addition to mapping guest to physical
memory, isolation is provided that this device can not access memory
belongs to other guests or hypervisor.</p>
<p>Another innovation that helps interrupts scale to large numbers of VMs
is called Message Signaled Interrupts (MSI). Rather than relying on
physical interrupt pins to be associated with a guest, MSI transforms
interrupts into messages that are more easily virtualized (scaling to
thousands of individual interrupts). MSI has been available since PCI
version 2.2 but is also available in PCI Express (PCIe), where it allows
fabrics to scale to many devices. MSI is ideal for I/O virtualization,
as it allows isolation of interrupt sources (as opposed to physical pins
that must be multiplexed or routed through software).</p>
</div>
<div class="section" id="hypervisor-support-for-device-passthrough">
<span id="h-x2z9ky9whfl4"></span><h5>2.3.5.2 hypervisor support for device passthrough<a class="headerlink" href="#hypervisor-support-for-device-passthrough" title="Permalink to this headline">¶</a></h5>
<p>By using the latest virtualization-enhanced processor architectures, a
number of hypervisors and virtualization solutions can support device
pass-through (using VT-d), including Xen and KVM, as well as this open
source ACRN hypervisor. In most cases, the guest operating system (User
OS) must be compiled to support pass-through, which is available as a
kernel build-time option. Hiding the devices from the host VM may also
be required (as is done with Xen using pciback). Some restrictions apply
in PCI, for example, PCI devices behind a PCIe-to-PCI bridge must be
assigned to the same guest OS. PCIe does not have this restriction.</p>
</div>
</div>
<div class="section" id="acrn-i-o-mediator">
<span id="h-7brtlt85ttvh"></span><h4>2.3.6 ACRN I/O mediator<a class="headerlink" href="#acrn-i-o-mediator" title="Permalink to this headline">¶</a></h4>
<p>Figure 7 shows the flow of an example I/O emulation path. When a guest
execute an I/O instruction (PIO or MMIO), a VM exit happens. ACRN
hypervisor takes the control, and apply further process base on the VM
exit reason, which is a VMX_EXIT_REASON_IO_INSTRUCTION for PIO access.
ACRN hypervisor will then fetch and decide the guest instruction, and
realized it is an PIO instruction (in AL, 20h in this example), and put
the decoded information (including the PIO address, size of access,
read/write, and target register) into the shared page, and
notify/interrupt SOS to process.
The virtio and hypervisor service module (VHM) in SOS received the
interrupt, and query the IO request ring to get the PIO instruction
details. It will check to see if any in kernel device claimed the
ownership of the IO port: if a kernel module claimed it, the kernel
module is activated to execute its processing APIs, otherwise, VHM
module will leave the IO request in the shared page and wake up the
device model thread to process.
ACRN device model follow same mechanism of the VHM does. The I/O
processing thread of device model queries the IO request ring to get the
PIO instruction details and check to see if any (guest) device emulation
modules claimed the ownership of the IO port: if a module claimed it,
the module is invoked to execute its processing APIs.
After the ACRN device module completes the emulation (port IO 20h access
in this example), say uDev1 here. The uDev1 will put the result into the
shared page. That is the register AL in this example. ACRN device model
will then return the control to ACRN hypervisor to indicate the
completion of an IO instruction emulation, typically thru VHM/hypercall.
The ACRN hypervisor then knows the completion of IO emulation, and copy
the result to the guest register context, advance the guest IP to
indicate the completion of instruction execution, and resume the guest.
MMIO path is very similar, except the VM exit reason is different. MMIO
access usually is trapped thru VMX_EXIT_REASON_EPT_VIOLATION in
hypervisor. The rest are same.
<img alt="image6" src="introduction/images/image1.png" /></p>
<p>Figure 7 I/O Emulation Path</p>
</div>
<div class="section" id="virtio-framework-architecture">
<span id="h-dxis9thdolvb"></span><h4>2.3.7 VirtIO framework architecture<a class="headerlink" href="#virtio-framework-architecture" title="Permalink to this headline">¶</a></h4>
<p>The Virtio is an abstraction for a set of common emulated devices in any
type of hypervisor. In this open source reference stack, our
implementation is compatible with Virtio spec 0.9 and 1.0.&nbsp;The purpose
of virtio and the specification is that virtual environments and guests
should have a straightforward, efficient, standard and extensible
mechanism for virtual devices, rather than boutique per-environment or
per-OS mechanisms.</p>
<p>Virtio provides a common frontend driver framework which not only
standardizes device interfaces, but also increases code reuse across
different virtualization platforms.</p>
<p><img alt="image7" src="introduction/images/image2.png" /></p>
<p>Figure 8 Virtio Architecture</p>
<p>To better understand the Virtio, especially its usage in this open
source ACRN project, several key concepts of Virtio are highlighted
here:</p>
<p>Front-End virtio driver&nbsp;(a.k.a. frontend driver, or FE driver in this
document)</p>
<p>Virtio adopts a frontend-backend architecture, which enables a simple
but flexible framework for both frontend and backend virtio driver. The
FE driver provides a configure interface, pass messages, produce
requests, and notify backend virtio driver. As a result, the FE driver
is easy to implement and the performance overhead of emulating device is
eliminated.</p>
<p>Back-End virtio driver&nbsp;(a.k.a. backend driver, or BE driver in this
document)</p>
<p>Similar to FE driver, the BE driver, runs either in user-land or
kernel-land of host OS. The BE driver consumes requests from FE driver
and send them to the host’s native device driver. Once the requests are
done by the host native device driver, the BE driver notifies the FE
driver about the completeness of the requests.</p>
<p>Straightforward: virtio devices as standard devices on existing Buses</p>
<p>Instead of creating new device buses from scratch, virtio devices are
built on existing buses. This gives a straightforward way for both FE
and BE drivers to interact with each other. For example, FE driver could
read/write registers of the device, and the virtual device could
interrupt FE driver, on behalf of the BE driver, in case of something is
happening.
Currently virtio supports PCI/PCIe bus and MMIO bus. In this open source
project, only PCI/PCIe bus is supported, and all the virtio devices
share the same vendor ID 0x1AF4.</p>
<p>Efficient: batching operation is encouraged</p>
<p>Batching operation and deferred notification are important to achieve
high-performance I/O, since notification between FE and BE driver
usually involves an expensive exit of the guest. Therefore batching
operating and notification suppression are highly encouraged if
possible. This will give an efficient implementation for the performance
critical devices.</p>
<p>Standard: virtqueue</p>
<p>All the virtio devices share a standard ring buffer and descriptor
mechanism, which is called a virtqueue, shown in Figure 6. A virtqueue
is a queue of scatter-gather buffers and there are three important
methods on virtqueues: add_buf&nbsp;is for adding a request/response buffer
in a virtqueue, get_buf&nbsp;is for getting a response/request in a
virtqueue, and kick&nbsp;is for notifying the other side for a virtqueue to
consume buffers.
The virtqueues are created in guest physical memory by the FE drivers,
and the BE drivers only need to parse the virtqueue structures to obtain
the requests and get the requests done. How virtqueue is organized is
specific to User OS. In the implementation of virtio in Linux, the
virtqueue is implemented as a ring buffer structure called vring.</p>
<p>In this open source project, the virtqueue APIs can be leveraged
directly so that users don’t need to worry about the details of the
virtqueue. In the meantime, developers could also refer to User OS for
more details about the virtqueue implementations.</p>
<p>&nbsp;Extensible: feature bits</p>
<p>A simple extensible feature negotiation mechanism for each virtual
device and its driver, so that each virtual device could claim its
device specific features while the corresponding driver could respond to
the device with the subset of features the driver understands. The
feature mechanism enables forward and backward compatibility for the
virtual device and driver.</p>
<p>In this open source reference stack, also we implemented 2 parts: user
land and kernel space:</p>
<p><img alt="image8" src="introduction/images/image6.png" /></p>
<p>Figure 9&nbsp;- Virtio Framework – User Land</p>
<p>In user land of Virtio framework, the implement is compatible with
Virtio Spec 0.9/1.0, and the VBS-U static link with DM, and communicate
with Device Model through PCIe I/F:</p>
<p>PIO/MMIO or MSI/MSIx. VBS-U access virtio APIs through user space vring
service API helpers, User space vring service API helpers access shared
ring through remote memory map (mmap), VHM maps UOS memory with help of
ACRN Hypervisor.</p>
<p><img alt="image9" src="introduction/images/image4.png" /></p>
<p>Figure 10&nbsp;- Virtio Framework – Kernel Space</p>
<p>VBS-U offloads data plane processing to VBS-K, VBS-U initializes VBS-K
at the right timings, for example. FE driver sets
VIRTIO_CONFIG_S_DRIVER_OK, in order to avoid unnecessary device
configuration changes in running time, it allow VBS-K to access shared
rings through VBS-K virtqueue APIs and VBS-K virtqueue APIs are similar
to VBS-U virtqueue APIs. &nbsp;VBS-K registers as VHM client(s) to handle a
continuous range of registers</p>
<p>, One or multiple VHM-client for each VBS-K and could be single
VHM-client for all VBS-Ks as well. VBS-K notifies FE throughVHM
interrupt APIs.</p>
<div class="c34"><p><a class="reference external" href="#cmnt_ref1">[a]</a>examples?</p>
</div><div class="c34"><p><a class="reference external" href="#cmnt_ref2">[b]</a>good suggestion, need engineer team to input</p>
</div><div class="c34"><p><a class="reference external" href="#cmnt_ref3">[c]</a><a class="reference external" href="mailto:+jack&#46;ren&#37;&#52;&#48;intel&#46;com">+jack<span>&#46;</span>ren<span>&#64;</span>intel<span>&#46;</span>com</a> &nbsp;who can help to give an
example?</p>
</div><div class="c34"><p><a class="reference external" href="#cmnt_ref4">[d]</a>Dong, Eddie</p>
</div></div>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Project ACRN.
      Last updated on Mar 08, 2018.

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'v 0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>